{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ch2. exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "housing = pd.read_csv('housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude               0\n",
       "latitude                0\n",
       "housing_median_age      0\n",
       "total_rooms             0\n",
       "total_bedrooms        207\n",
       "population              0\n",
       "households              0\n",
       "median_income           0\n",
       "median_house_value      0\n",
       "ocean_proximity         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측값 있는지 확인\n",
    "housing.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측값 제거\n",
    "housing = housing.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEAR BAY', '<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'ISLAND'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categorical variable의 범주 확인\n",
    "housing.ocean_proximity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical variable -> dummy variable로 만들기\n",
    "enc = OneHotEncoder()\n",
    "\n",
    "ocean_proximity = enc.fit_transform(np.array(housing.ocean_proximity).reshape(-1,1)).toarray()\n",
    "ocean_proximity = pd.DataFrame(ocean_proximity)\n",
    "ocean_proximity.columns = enc.categories_\n",
    "\n",
    "# 만들어준 variable을 기존 데이터와 concat\n",
    "housing = pd.concat([housing.reset_index(drop=True), ocean_proximity], axis=1)\n",
    "housing = housing.drop('ocean_proximity', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 추가\n",
    "housing['rooms_per_households'] = housing.total_rooms/housing.households\n",
    "housing['population_per_households'] = housing.population/housing.households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16346, 16) (4087, 16)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "train, test = train_test_split(housing, test_size=0.2, random_state=79)\n",
    "# split 잘 되었는지 dimension 확인\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립변수와 종속변수(target)으로 나누기\n",
    "train_x = train.drop('median_house_value', axis=1)\n",
    "train_y = train.median_house_value\n",
    "\n",
    "test_x = test.drop('median_house_value', axis=1)\n",
    "test_y = test.median_house_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "scaling = StandardScaler()\n",
    "train_x_scaled = scaling.fit_transform(train_x)\n",
    "test_x_scaled = scaling.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse of 1 th model : 80975.45267658445\n",
      "rmse of 2 th model : 110778.91954075838\n",
      "rmse of 3 th model : 119620.85398652202\n",
      "rmse of 4 th model : 120885.09660917179\n",
      "rmse of 5 th model : 117136.81257662126\n",
      "rmse of 6 th model : 120682.04730071164\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터를 다양하게 조정한 여섯 가지 모델\n",
    "svr_linear_10 = SVR(kernel='linear', C=10)\n",
    "svr_linear_1 = SVR(kernel='linear')\n",
    "svr_poly_10 = SVR(kernel='poly', C=10)\n",
    "svr_poly_1 = SVR(kernel='poly')\n",
    "svr_rbf_10 = SVR(kernel='rbf', C=10)\n",
    "svr_rbf_1 = SVR(kernel='rbf')\n",
    "\n",
    "models = [svr_linear_10, svr_linear_1, svr_poly_10, svr_poly_1, svr_rbf_10, svr_rbf_1]\n",
    "\n",
    "# 모델을 넣으면 fit->pred->rmse를 계산해주는 함수\n",
    "def fitting_svr(model) :\n",
    "    fitted_model = model.fit(train_x_scaled, train_y)\n",
    "    pred_y = model.predict(test_x_scaled)\n",
    "    rmse = np.sqrt(mean_squared_error(test_y, pred_y))\n",
    "    return rmse\n",
    "\n",
    "# 여섯 가지 모델에 대한 rmse 구하기\n",
    "for i in range(len(models)) :\n",
    "    rmse = fitting_svr(models[i])\n",
    "    print ('rmse of',i+1,'th model :',rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ch2. exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 19}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위에서 가장 좋았던 linear SVR에 대한 하이퍼 파라미터를 조정\n",
    "param_grid = {'C':[0.1,0.3,0.5,0.7,0.9,1,3,5,7,9,11,13,15,17,19,25,30]}\n",
    "randomized_cv = RandomizedSearchCV(SVR(kernel='linear'), param_grid, n_iter=5, n_jobs=-1, cv=3, random_state=79)\n",
    "\n",
    "svr_linear_cv = randomized_cv.fit(train_x_scaled, train_y)\n",
    "svr_linear_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77347.73424206937"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위에서 나온 best parameter로 fit->pred->rmse 구하기\n",
    "fitting_svr(SVR(kernel='linear', C=list(svr_linear_cv.best_params_.values())[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ch3. exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data -> train test split\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "x, y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "train_x, test_x, train_y, test_y = x[:60000], x[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn classifier의 하이퍼 파라미터 : n_neighbors 조정\n",
    "param_grid = {'n_neighbors':list(range(1,100))}\n",
    "randomized_cv = RandomizedSearchCV(KNeighborsClassifier(), param_grid, n_iter=5, n_jobs=-1, cv=3, random_state=79)\n",
    "\n",
    "knn_cv = randomized_cv.fit(train_x, train_y)\n",
    "knn_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 나온 best parameter로 fit->pred->accuracy 구하기\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=list(knn_cv.best_params_.values())[0])\n",
    "knn_fit = knn_clf.fit(train_x, train_y)\n",
    "pred_y = knn_clf.predict(test_x)\n",
    "\n",
    "accuracy_score(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ch3. exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "train = pd.read_csv('train_data.csv')\n",
    "test = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index\n",
    "train.index = train['PassengerId']\n",
    "train = train.drop('PassengerId', axis=1)\n",
    "\n",
    "test.index = test['PassengerId']\n",
    "test = test.drop('PassengerId', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived       0\n",
       "Sex            0\n",
       "Age            0\n",
       "Fare           0\n",
       "Pclass_1       0\n",
       "Pclass_2       0\n",
       "Pclass_3       0\n",
       "Family_size    0\n",
       "Title_1        0\n",
       "Title_2        0\n",
       "Title_3        0\n",
       "Title_4        0\n",
       "Emb_1          0\n",
       "Emb_2          0\n",
       "Emb_3          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set 결측값 확인\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived       0\n",
       "Sex            0\n",
       "Age            0\n",
       "Fare           0\n",
       "Pclass_1       0\n",
       "Pclass_2       0\n",
       "Pclass_3       0\n",
       "Family_size    0\n",
       "Title_1        0\n",
       "Title_2        0\n",
       "Title_3        0\n",
       "Title_4        0\n",
       "Emb_1          0\n",
       "Emb_2          0\n",
       "Emb_3          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set 결측값 확인\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립변수, 종속변수(target)로 나누기\n",
    "train_x = train.drop('Survived', axis=1)\n",
    "train_y = train.Survived\n",
    "\n",
    "test_x = test.drop('Survived', axis=1)\n",
    "test_y = test.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "scaling = StandardScaler()\n",
    "train_x_scaled = scaling.fit_transform(train_x)\n",
    "test_x_scaled = scaling.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 136, 'max_features': 'log2', 'max_depth': 9}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest classifier hyperparameter tuning\n",
    "param_grid = {'n_estimators':list(range(1,200)),\n",
    "             'max_depth':list(range(1,10)),\n",
    "             'max_features':['auto','sqrt','log2']}\n",
    "randomized_cv = RandomizedSearchCV(RandomForestClassifier(), param_grid, n_iter=5, n_jobs=-1, cv=3, random_state=79)\n",
    "\n",
    "rf_cv = randomized_cv.fit(train_x_scaled, train_y)\n",
    "rf_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위에서 나온 best parameter로 fit->pred->accuracy 구하기\n",
    "rf_clf = RandomForestClassifier(n_estimators=list(rf_cv.best_params_.values())[0],\n",
    "                               max_features=list(rf_cv.best_params_.values())[1],\n",
    "                               max_depth=list(rf_cv.best_params_.values())[2])\n",
    "rf_fit = rf_clf.fit(train_x_scaled, train_y)\n",
    "pred_y = rf_clf.predict(test_x_scaled)\n",
    "\n",
    "accuracy_score(test_y, pred_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
